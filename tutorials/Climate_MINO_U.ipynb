{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efdfa33f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## load path\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../models')\n",
    "from pathlib import Path\n",
    "\n",
    "## load utils \n",
    "from util.util import *\n",
    "\n",
    "# we provide two realizations of GP on sphere, the commented one is slower\n",
    "#from util.ofm_OT_likelihood_sphere_seq_mino import * \n",
    "\n",
    "from util.ofm_OT_likelihood_seq_mino import *\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import binned_statistic\n",
    "import matplotlib.tri as tri\n",
    "from util.metrics import *\n",
    "import time\n",
    "\n",
    "## load modules \n",
    "from models.mino_unet import MINO\n",
    "from models.mino_modules.decoder_perceiver import DecoderPerceiver\n",
    "from models.mino_modules.encoder_supernodes_gno_cross_attention import EncoderSupernodes\n",
    "from models.mino_modules.conditioner_timestep import ConditionerTimestep\n",
    "\n",
    "from models.mino_modules.modules.unet_nD import UNetModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277e7183",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dims = [32,16] # latent\n",
    "x_dim = 3\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "#spath = Path('../trash/GP')\n",
    "spath = Path('./saved_models/MINO_U_Climate')\n",
    "\n",
    "spath.mkdir(parents=True, exist_ok=True)\n",
    "saved_model = True # save model\n",
    "\n",
    "# GP hyperparameters\n",
    "kernel_length=0.05 ## maybe kernel length = 0.02 # (or 0.01)\n",
    "kernel_variance=1\n",
    "nu = 0.5 # default\n",
    "\n",
    "\n",
    "# model hyperparameters\n",
    "dim = 256 # sup-node\n",
    "num_heads = 4\n",
    "unet_dims = (dim, *query_dims) \n",
    "unet_channels = 96 \n",
    "num_res_blocks=1\n",
    "attention_res = '4'\n",
    "\n",
    "\n",
    "## training parameters\n",
    "epochs = 480\n",
    "sigma_min=1e-4\n",
    "batch_size = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d75b0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "_NUM_LONGS = 90\n",
    "_NUM_LATS = 46 \n",
    "\n",
    "############\n",
    "# generate a grid on the sphere\n",
    "longs, lats =  np.mgrid[0:2*np.pi:(_NUM_LONGS+1)*1j, 0:np.pi:_NUM_LATS*1j]\n",
    "\n",
    "longs, lats = longs[:-1,:], lats[:-1,:]\n",
    "\n",
    "other_points_xs = np.sin(lats) * np.cos(longs)\n",
    "other_points_ys = np.sin(lats) * np.sin(longs)\n",
    "other_points_zs = np.cos(lats)\n",
    "\n",
    "other_points = np.c_[np.ravel(other_points_xs),\n",
    "                     np.ravel(other_points_ys),\n",
    "                     np.ravel(other_points_zs)]\n",
    "\n",
    "n_pos = other_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "039984c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_query_sphere(num_longs, num_lats):\n",
    "    longs, lats =  np.mgrid[0:2*np.pi:(num_longs+1)*1j, 0:np.pi:num_lats*1j]\n",
    "\n",
    "    longs, lats = longs[:-1,2:-2], lats[:-1,2:-2]\n",
    "\n",
    "    print(\"longs:{}\".format(longs.shape))\n",
    "    other_points_xs = np.sin(lats) * np.cos(longs)\n",
    "    other_points_ys = np.sin(lats) * np.sin(longs)\n",
    "    other_points_zs = np.cos(lats)\n",
    "\n",
    "    query_pos = np.c_[np.ravel(other_points_xs),\n",
    "                         np.ravel(other_points_ys),\n",
    "                         np.ravel(other_points_zs)]\n",
    "    \n",
    "    return query_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d3b7df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longs:(32, 16)\n"
     ]
    }
   ],
   "source": [
    "#query_pos = latent_query_sphere(num_longs=48, num_lats=28) #(32, 16) #->21144\n",
    "query_pos_input = latent_query_sphere(num_longs=32, num_lats=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72cee52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('../dataset/weather/train_climate.npy')\n",
    "x_train = torch.Tensor(x_train[:,2:3]).permute(0,1,3,2) # 0:2 (longitude, latitude)\n",
    "x_train = torch.flatten(x_train, start_dim=2)\n",
    "\n",
    "\n",
    "n_pos = torch.Tensor(n_pos)\n",
    "pos_data = n_pos.unsqueeze(0).repeat(len(x_train), 1, 1).permute(0, 2, 1)\n",
    "\n",
    "query_pos_input = torch.Tensor(query_pos_input).permute(1,0)\n",
    "train_dataset = SimDataset(x_train, pos_data, query_pos_input)\n",
    "\n",
    "loader_tr =  DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=SimulationCollator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677f39f4",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de074b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioner = ConditionerTimestep(\n",
    "    dim=dim\n",
    ")\n",
    "model = MINO(\n",
    "    conditioner=conditioner,\n",
    "    encoder=EncoderSupernodes(\n",
    "        input_dim=1,\n",
    "        ndim=3,\n",
    "        radius= 0.2,\n",
    "\n",
    "        enc_dim=dim,\n",
    "        enc_num_heads=num_heads,\n",
    "        enc_depth=2,\n",
    "        cond_dim=conditioner.cond_dim,\n",
    "    ),\n",
    "    \n",
    "\n",
    "    processor=UNetModelWrapper(dim=unet_dims, num_channels=unet_channels,\n",
    "                                          num_res_blocks=num_res_blocks,\n",
    "                                          num_heads=num_heads, set_cond=False,\n",
    "                                          attention_resolutions=attention_res),\n",
    "    \n",
    "    decoder=DecoderPerceiver(\n",
    "        input_dim=dim,\n",
    "        output_dim=1,\n",
    "        ndim=3,\n",
    "        dim=dim,\n",
    "        num_heads=num_heads,\n",
    "        depth=2,\n",
    "        unbatch_mode=\"dense_to_sparse_unpadded\",\n",
    "        cond_dim=conditioner.cond_dim,\n",
    "    ),\n",
    ")\n",
    "model = model.to(device)\n",
    "#print(f\"parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76f44ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.8)\n",
    "fmot = OFMModel(model, kernel_length=kernel_length, kernel_variance=kernel_variance, nu=nu, sigma_min=sigma_min, device=device, x_dim=x_dim, n_pos=n_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1cd9123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fmot.train(loader_tr, optimizer, epochs=epochs, scheduler=scheduler, eval_int=int(0), save_int=int(480), generate=False, save_path=spath,saved_model=saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c732994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c3da814",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed11d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_path = os.path.join(spath, 'epoch_480.pt')\n",
    "checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)\n",
    "model.load_state_dict(checkpoint, strict=False)\n",
    "fmot = OFMModel(model, kernel_length=kernel_length, kernel_variance=kernel_variance, nu=nu, sigma_min=sigma_min, device=device, x_dim=x_dim, n_pos=n_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d33db7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_pos_latent = query_pos_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad9bf6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_meta_info(batch_size, query_pos, n_pos):\n",
    "\n",
    "    n_pos = n_pos\n",
    "    pos_data = n_pos.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "    \n",
    "    query_pos_data = query_pos.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "\n",
    "    collated_batch = {}\n",
    "\n",
    "\n",
    "    collated_batch[\"input_pos\"] = pos_data.permute(0, 2, 1)\n",
    "    collated_batch['query_pos']= query_pos_data\n",
    "\n",
    "\n",
    "    \n",
    "    return collated_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a8003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    X_alt = []\n",
    "    for i in range(26):\n",
    "        collated_batch =  gen_meta_info(batch_size=100, n_pos=n_pos, query_pos=query_pos_input)\n",
    "        pos, query_pos = collated_batch['input_pos'], collated_batch['query_pos']\n",
    "        X_temp = fmot.sample(pos=pos.to(device), query_pos=query_pos.to(device), n_samples=100, n_channels=1, n_eval=5).cpu()\n",
    "    \n",
    "        #X_temp = fmot.sample(pos=pos_data[:200].to(device), n_samples=200, n_eval=10).cpu()\n",
    "        X_alt.append(X_temp)\n",
    "        \n",
    "    X_alt = torch.vstack(X_alt).squeeze()\n",
    "    \n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a8aa2f",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test =  np.load('../dataset/weather/test_climate.npy')\n",
    "\n",
    "x_test = torch.Tensor(x_test[:,2:3]).permute(0,1,3,2) # (longitude, latitude)\n",
    "x_test = torch.flatten(x_test, start_dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "swd_value = swd_stable(X=X_alt, Y=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_value = unbiased_mmd2_torch(X=X_alt, Y=x_test, device=device)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
